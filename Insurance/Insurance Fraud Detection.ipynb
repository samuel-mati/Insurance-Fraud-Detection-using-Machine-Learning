# Insurance Fraud Detection Project
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
import seaborn as sns
%matplotlib inline
## Data Summary
#load the dataset

df=pd.read_excel(r"../insurance_fraud_data.xlsx")

df.head()
df.shape
df.describe()
df.info()
categorical_features=df.select_dtypes(include='object').columns
print(categorical_features)
numerical_features=df.select_dtypes(include='int').columns
print(numerical_features)
## Exporatory Data Analysis Report
## 1. Univariate Analysis
df['fraud_reported'].head()
sns.countplot(x='fraud_reported', data=df)
plt.show()
### b. Histograms
plt.figure(figsize=(15,6))
plt.hist(df['age'],bins=30)
plt.show()
plt.figure(figsize=(15,6))
plt.hist(df['months_as_customer'],bins=20)
plt.show()
plt.figure(figsize=(10,4))
plt.hist(df['witnesses'],bins=10)
plt.show()
### Boxplots
# List of numerical columns
numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns

# Set up the figure
plt.figure(figsize=(15, 10))

# Create box plots for each numerical column
for i, column in enumerate(numerical_columns):
    plt.subplot(5, 4, i + 1)  
    sns.boxplot(y=df[column], color='lightgreen')
    plt.title(column)
    plt.ylabel('Value')

plt.tight_layout()  
plt.show()
df_new=df.copy()
df_new['fraud_reported'].head()
def replace_values(value):
    if value == "Y":
        return 1
    else:
        return 0

# Apply the function to the 'fraud_reported' column
df_new['fraud_reported'] = df_new['fraud_reported'].apply(replace_values)

df_new['fraud_reported'].head()
## Bivariate Analysis
# Count plot for insured_sex vs. fraud_reported
plt.figure(figsize=(8, 5))
sns.countplot(x='insured_sex',  data=df_new, palette='pastel')
plt.title('Fraud Reported by Insured Sex')
plt.xlabel('Insured Sex')
plt.ylabel('Count')
plt.legend(title='Fraud Reported', loc='upper right')
plt.show()

# Box plot for policy_annual_premium vs. fraud_reported
plt.figure(figsize=(8, 5))
sns.boxplot(x='fraud_reported', y='policy_annual_premium', data=df_new, palette='pastel')
plt.title('Policy Annual Premium by Fraud Reported')
plt.xlabel('Fraud Reported')
plt.ylabel('Policy Annual Premium')
plt.show()

corr_df= df_new.select_dtypes(include=['int64', 'float64'])
correlation= corr_df.corr()
fault_corr=correlation.sort_values(by='fraud_reported', ascending=False)
print(fault_corr)
plt.figure(figsize=(10,8))
sns.heatmap(fault_corr,cmap='coolwarm')
plt.show()
## Normalization
### 1. Insured Education Level
values=df_new['insured_education_level'].unique()
print(values)
plt.figure(figsize=(10,4))
sns.countplot(y='insured_education_level', data=df_new, order=df_new['insured_education_level'].value_counts().index[:7])
plt.show()
### 2.Insured Sex
values=df_new['insured_sex'].unique()
print(values)

### 3. Incident Type
values=df_new['incident_type'].unique()
print(values)
plt.figure(figsize=(10,4))
sns.countplot(y='incident_type', data=df_new, order=df_new['incident_type'].value_counts().index[:7])
plt.show()
### 4. Collission Type
values=df_new['collision_type'].unique()
print(values)
plt.figure(figsize=(10,4))
sns.countplot(y='collision_type', data=df_new, order=df_new['collision_type'].value_counts().index[:7])
plt.show()
### 5. Incident Severity
values=df_new['incident_severity'].unique()
print(values)
plt.figure(figsize=(10,4))
sns.countplot(y='incident_severity', data=df_new, order=df_new['incident_severity'].value_counts().index[:7])
plt.show()
### 6. Property Damage
values=df_new['property_damage'].unique()
print(values)
plt.figure(figsize=(10,4))
sns.countplot(y='property_damage', data=df_new, order=df_new['property_damage'].value_counts().index[:7])
plt.show()
### 7. Police Report Available
values=df_new['police_report_available'].unique()
print(values)
columns_to_normalize= [
    'insured_education_level',
    'insured_sex',
    'incident_type',
    'collision_type',
    'incident_severity',
    'property_damage',
    'police_report_available'
]

for column in columns_to_normalize:
    unique_values = df_new[column].unique()
    print(f"Unique values in '{column}':")
    print(unique_values)

plt.figure(figsize=(10,4))
sns.countplot(y='incident_type', data=df_new, order=df_new['incident_type'].value_counts().index[:7])
plt.show()
## Normalization
def normalize(value):
    if value == 'YES':
        return 1
    elif value == 'NO':
        return 0
    else:
        return 0.5

df_new['police_report_available']=df_new['police_report_available'].apply(normalize)
df_new['police_report_available'].head()
plt.figure(figsize=(10,4))
sns.countplot(y='police_report_available', data= df_new)
plt.show()
def normalize(value):
    if value == "High School":
        return 1
    elif value == "College":
        return 2
    elif value == "Associate":
        return 3
    elif value == "Masters":
        return 4
    elif value == "JD":
        return 5
    elif value == "MD":
        return 6
    elif value == "PhD":
        return 7
    else:
        return None

# Apply the function to the 'feature' column of the DataFrame
df_new['insured_education_level'] = df_new['insured_education_level'].apply(normalize)

df_new['insured_education_level'].head()
incident_severity_mapping = {
    'Major Damage': 3,
    'Minor Damage': 1,
    'Total Loss': 4,
    'Trivial Damage': 2
}

df_new['incident_severity'] = df_new['incident_severity'].map(incident_severity_mapping)
df_new['incident_severity'].head()
property_damage_mapping = {
    'YES': 1,
    'NO': 0,
    '?': 0.5
}

df_new['property_damage']=df_new['property_damage'].map(property_damage_mapping)

df_new['property_damage'].head()

## Final Dataset Review
df_new.describe()
df_corr=df_new.select_dtypes(include=['int64','float64'])

corr=df_corr.corr()
plt.figure(figsize=(10,8))

sns.heatmap(corr[['fraud_reported']], annot=True)
plt.show()
## Final Dataset Correlation Report
import sweetviz as sv
report=sv.analyze(df_corr)

report.show_html('df_corr_report.html')
print(corr[['fraud_reported']])
# Training the Model
from sklearn.model_selection import train_test_split
X= df_corr.drop('fraud_reported', axis=1)
y=df_corr['fraud_reported']
X.head()
y.head()
X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.2, random_state=42)
X_train.shape

